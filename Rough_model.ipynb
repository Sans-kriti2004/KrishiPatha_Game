{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "840fe9d4",
   "metadata": {},
   "source": [
    "### Yield Prediction Model - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f7bf251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "433289d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility metrics\n",
    "def rmse(y_true, y_pred):\n",
    "    return math.sqrt(((y_true - y_pred) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e49b9683",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"global_large_12year_yield_dataset.csv\");\n",
    "\n",
    "# Drop rows with missing critical features or target\n",
    "df = df.dropna(subset=['yield_kg_ha'])\n",
    "# select features automatically (all numeric except lat/lon/year can be kept)\n",
    "# If there are non-numeric columns, drop them or encode before use.\n",
    "# We will pick a conservative set: numeric columns except target.\n",
    "target_col = 'yield_kg_ha'\n",
    "feature_cols = [c for c in df.columns if c != target_col and np.issubdtype(df[c].dtype, np.number)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a875bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[feature_cols].values\n",
    "y = df[target_col].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b712ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36a51232",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchTreeNode:\n",
    "    __slots__ = ('pred', 'feat', 'thresh', 'left', 'right')\n",
    "    def __init__(self, pred=None, feat=None, thresh=None, left=None, right=None):\n",
    "        self.pred = pred\n",
    "        self.feat = feat\n",
    "        self.thresh = thresh\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "def mse_loss(y):\n",
    "    if len(y) == 0:\n",
    "        return 0.0\n",
    "    return float(np.var(y) * len(y))\n",
    "\n",
    "def best_split_quick(X, y, feature_indices, n_thresholds=10, min_samples_leaf=3):\n",
    "    \"\"\"\n",
    "    For speed, evaluate thresholds at feature percentiles (n_thresholds).\n",
    "    Returns (best_feat, best_thresh, best_score) or (None, None, None) if no split.\n",
    "    \"\"\"\n",
    "    n, d = X.shape\n",
    "    best_feat, best_thresh, best_score = None, None, float('inf')\n",
    "    for feat in feature_indices:\n",
    "        col = X[:, feat]\n",
    "        # unique values check\n",
    "        if np.all(col == col[0]):\n",
    "            continue\n",
    "        # candidate thresholds: percentiles\n",
    "        percentiles = np.linspace(5, 95, n_thresholds)\n",
    "        thresh_candidates = np.percentile(col, percentiles)\n",
    "        for thresh in thresh_candidates:\n",
    "            left_mask = col <= thresh\n",
    "            right_mask = ~left_mask\n",
    "            # ensure minimum samples in each leaf\n",
    "            if left_mask.sum() < min_samples_leaf or right_mask.sum() < min_samples_leaf:\n",
    "                continue\n",
    "            score = mse_loss(y[left_mask]) + mse_loss(y[right_mask])\n",
    "            if score < best_score:\n",
    "                best_feat = feat\n",
    "                best_thresh = float(thresh)\n",
    "                best_score = float(score)\n",
    "    if best_feat is None:\n",
    "        return None, None, None\n",
    "    return best_feat, best_thresh, best_score\n",
    "\n",
    "def build_scratch_tree(X, y, depth=0, max_depth=6, min_samples_leaf=5):\n",
    "    # stopping\n",
    "    if depth >= max_depth or len(y) <= 2*min_samples_leaf or np.all(y == y[0]):\n",
    "        return ScratchTreeNode(pred=float(np.mean(y)))\n",
    "    m, d = X.shape\n",
    "    # random subset of features (sqrt rule)\n",
    "    k = max(1, int(math.sqrt(d)))\n",
    "    features = np.random.choice(d, k, replace=False)\n",
    "    feat, thresh, score = best_split_quick(X, y, features, n_thresholds=8, min_samples_leaf=min_samples_leaf)\n",
    "    if feat is None:\n",
    "        return ScratchTreeNode(pred=float(np.mean(y)))\n",
    "    left_idx = X[:, feat] <= thresh\n",
    "    right_idx = ~left_idx\n",
    "    # recursive build\n",
    "    left = build_scratch_tree(X[left_idx], y[left_idx], depth+1, max_depth, min_samples_leaf)\n",
    "    right = build_scratch_tree(X[right_idx], y[right_idx], depth+1, max_depth, min_samples_leaf)\n",
    "    return ScratchTreeNode(pred=None, feat=feat, thresh=thresh, left=left, right=right)\n",
    "\n",
    "def predict_tree(node, x):\n",
    "    while node.pred is None:\n",
    "        if x[node.feat] <= node.thresh:\n",
    "            node = node.left\n",
    "        else:\n",
    "            node = node.right\n",
    "    return node.pred\n",
    "\n",
    "class ScratchRandomForest:\n",
    "    def __init__(self, n_trees=10, max_depth=6, min_samples_leaf=5, bootstrap=True, random_state=None):\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.bootstrap = bootstrap\n",
    "        self.trees = []\n",
    "        self.random_state = random_state\n",
    "        if random_state is not None:\n",
    "            random.seed(random_state)\n",
    "            np.random.seed(random_state)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n = X.shape[0]\n",
    "        self.trees = []\n",
    "        for t in range(self.n_trees):\n",
    "            if self.bootstrap:\n",
    "                idx = np.random.choice(n, n, replace=True)\n",
    "                Xb = X[idx]\n",
    "                yb = y[idx]\n",
    "            else:\n",
    "                Xb = X\n",
    "                yb = y\n",
    "            tree = build_scratch_tree(Xb, yb, max_depth=self.max_depth, min_samples_leaf=self.min_samples_leaf)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        preds = np.zeros((len(self.trees), X.shape[0]), dtype=float)\n",
    "        for i, tree in enumerate(self.trees):\n",
    "            preds[i] = np.array([predict_tree(tree, x) for x in X])\n",
    "        return preds.mean(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d690fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training scratch RF ===\n",
      "Scratch RF training time: 1.22s\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Training scratch RF ===\")\n",
    "start_time = time.time()\n",
    "scratch_rf = ScratchRandomForest(n_trees=12, max_depth=7, min_samples_leaf=5, random_state=42)\n",
    "# We will train on UNscaled numeric features (X_train) to keep split thresholds interpretable\n",
    "scratch_rf.fit(X_train, y_train)\n",
    "t_scratch_train = time.time() - start_time\n",
    "print(f\"Scratch RF training time: {t_scratch_train:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d1fa6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scratch RF predict time: 0.01s\n",
      "Scratch RF  -> RMSE: 281.61, R2: 0.965\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "y_pred_scratch = scratch_rf.predict(X_test)\n",
    "t_scratch_pred = time.time() - start_time\n",
    "print(f\"Scratch RF predict time: {t_scratch_pred:.2f}s\")\n",
    "rmse_scratch = rmse(y_test, y_pred_scratch)\n",
    "r2_scratch = r2_score(y_test, y_pred_scratch)\n",
    "print(f\"Scratch RF  -> RMSE: {rmse_scratch:.2f}, R2: {r2_scratch:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb08a635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save scratch model\n",
    "with open(\"rf_scratch.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scratch_rf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0949d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f4cc6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training scikit-learn RandomForestRegressor ===\n",
      "sklearn RF training time: 0.71s\n",
      "sklearn RF predict time: 0.04s\n",
      "sklearn RF -> RMSE: 273.80, R2: 0.967\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Training scikit-learn RandomForestRegressor ===\")\n",
    "start_time = time.time()\n",
    "rf_sklearn = RandomForestRegressor(n_estimators=200, max_depth=20, n_jobs=-1, random_state=42)\n",
    "rf_sklearn.fit(X_train_scaled, y_train)\n",
    "t_sklearn_train = time.time() - start_time\n",
    "print(f\"sklearn RF training time: {t_sklearn_train:.2f}s\")\n",
    "\n",
    "# Predict and evaluate\n",
    "start_time = time.time()\n",
    "y_pred_sklearn = rf_sklearn.predict(X_test_scaled)\n",
    "t_sklearn_pred = time.time() - start_time\n",
    "rmse_sklearn = rmse(y_test, y_pred_sklearn)\n",
    "r2_sklearn = r2_score(y_test, y_pred_sklearn)\n",
    "print(f\"sklearn RF predict time: {t_sklearn_pred:.2f}s\")\n",
    "print(f\"sklearn RF -> RMSE: {rmse_sklearn:.2f}, R2: {r2_sklearn:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcb7fd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparison ===\n",
      "Scratch RMSE: 281.61, R2: 0.965, train_time: 1.22s\n",
      "sklearn  RMSE: 273.80, R2: 0.967, train_time: 0.71s\n",
      "\n",
      "Notes:\n",
      "- scikit-learn model is usually faster (C-optimized) and more accurate; use it for production/demo.\n",
      "- scratch model helps illustrate RF internals (bootstrapping, feature subsampling, splitting).\n",
      "- If the scratch model is much worse, increase n_trees and/or max_depth, but runtime will rise.\n",
      "- You can compute feature importances from sklearn via rf_sklearn.feature_importances_\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Comparison ===\")\n",
    "print(f\"Scratch RMSE: {rmse_scratch:.2f}, R2: {r2_scratch:.3f}, train_time: {t_scratch_train:.2f}s\")\n",
    "print(f\"sklearn  RMSE: {rmse_sklearn:.2f}, R2: {r2_sklearn:.3f}, train_time: {t_sklearn_train:.2f}s\")\n",
    "print(\"\\nNotes:\")\n",
    "print(\"- scikit-learn model is usually faster (C-optimized) and more accurate; use it for production/demo.\")\n",
    "print(\"- scratch model helps illustrate RF internals (bootstrapping, feature subsampling, splitting).\")\n",
    "print(\"- If the scratch model is much worse, increase n_trees and/or max_depth, but runtime will rise.\")\n",
    "print(\"- You can compute feature importances from sklearn via rf_sklearn.feature_importances_\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf5b374",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
